{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProtoryNet_example.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e0RK6hBht6o",
        "outputId": "0ede3697-937e-42ad-bdd2-337d8a41c69c"
      },
      "source": [
        "!pip install scikit-learn-extra"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn-extra in /usr/local/lib/python3.7/dist-packages (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-extra) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-extra) (0.24.2)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-extra) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.23.0->scikit-learn-extra) (1.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.23.0->scikit-learn-extra) (2.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBGXozxbfkDf"
      },
      "source": [
        "!pip install -q pyyaml h5py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGU7rAmNfmjF"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "from sklearn_extra.cluster import KMedoids\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Concatenate, Dense, Input, LSTM, Embedding, Dropout, Activation, GRU, Flatten\n",
        "from datetime import datetime\n",
        "from scipy.spatial import distance_matrix\n",
        "import sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93YRvCsMfneI",
        "outputId": "64a56d45-67f0-4efc-8e90-37b9b44fdf3d"
      },
      "source": [
        "print(tf.__version__)\n",
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IkGwcJaN4f_"
      },
      "source": [
        "# Import datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqtOqokrfsBg"
      },
      "source": [
        "#dir = \"/content/drive/MyDrive/deep_learning/dl_research/interpretable_RNN/hotel/\"\n",
        "dir = \"datasets/hotel/\" #directory of the datasets\n",
        "with open (dir + 'y_train', 'rb') as fp:\n",
        "    y_train = pickle.load(fp)\n",
        "\n",
        "with open (dir + 'train_not_clean', 'rb') as fp:\n",
        "    train_not_clean = pickle.load(fp)\n",
        "\n",
        "with open (dir + 'test_not_clean', 'rb') as fp:\n",
        "    test_not_clean = pickle.load(fp)\n",
        "\n",
        "with open (dir + 'y_test', 'rb') as fp:\n",
        "    y_test = pickle.load(fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xct3r6rdOLev"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEbpMg8ygFxV"
      },
      "source": [
        "def gen_sents(para):\n",
        "    res = []\n",
        "    for p in para:\n",
        "        sents = p.split(\".\")\n",
        "        res.append(sents)\n",
        "    return res\n",
        "\n",
        "\n",
        "train_noclean_sents = gen_sents(train_not_clean)\n",
        "test_noclean_sents = gen_sents(test_not_clean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNM0Ud6CjIUw",
        "outputId": "71cf020f-33e5-418f-b871-07008ac86379"
      },
      "source": [
        "x_train = train_noclean_sents\n",
        "y_train = [int(y) for y in y_train]\n",
        "\n",
        "x_test = test_noclean_sents\n",
        "y_test = [int(y) for y in y_test]\n",
        "\n",
        "\n",
        "print('test_noclean_sents ', len(test_noclean_sents), len(test_noclean_sents[0]), test_noclean_sents[0])\n",
        "print('y_train: ', y_train[:10])\n",
        "print('y_test: ', y_test[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_noclean_sents  902 7 ['Share your room with roach or bug', ' Roach in the room but the staff said its just a bug not a roach, like that made it any better', ' Big hole in the bathroom wall were this bug/roach came out of', ' Wonder what other rodent will come out of the wall', 'Thank you for providing us with your feedback', ' I would like to apologize for any of the inconveniences you may have experienced during your time with us', ' I wish that I had been notified of your concerns before you had checked out and I would like to apologize on behalf of our staff']\n",
            "y_train:  [1, 1, 1, 0, 1, 1, 0, 0, 1, 1]\n",
            "y_test:  [0, 0, 1, 1, 0, 1, 0, 0, 0, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7J7G3engGRo",
        "outputId": "e4d16e3d-8c00-4282-c8ab-78b6e30d53a8"
      },
      "source": [
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
        "model = hub.load(module_url)\n",
        "print(\"module %s loaded\" % module_url)\n",
        "\n",
        "def embed(input):\n",
        "    return model(input)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "module https://tfhub.dev/google/universal-sentence-encoder/4 loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAkea6lngHvA",
        "outputId": "04a295e4-ba84-4ad7-ff98-65f9428e23cc"
      },
      "source": [
        "sample_sentences = []\n",
        "for p in train_noclean_sents[:2000]:\n",
        "    sample_sentences.extend(p)\n",
        "\n",
        "sample_sent_vect = embed(sample_sentences)\n",
        "print(sample_sent_vect)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[-0.02057868 -0.02088437  0.04719457 ... -0.05737035  0.0809434\n",
            "   0.03041554]\n",
            " [ 0.00906795 -0.03493962 -0.02079894 ... -0.04224585  0.0316922\n",
            "   0.02062659]\n",
            " [-0.05278952  0.00524477 -0.04006641 ... -0.05303752  0.07519066\n",
            "  -0.00645196]\n",
            " ...\n",
            " [ 0.0728193   0.00074287  0.02359985 ...  0.05585673  0.01407796\n",
            "  -0.039259  ]\n",
            " [-0.08977903  0.03925326  0.00559623 ... -0.00292801 -0.0292188\n",
            "  -0.04251549]\n",
            " [ 0.05419828 -0.03739635 -0.02377675 ... -0.02753167 -0.0237032\n",
            "   0.05560818]], shape=(23294, 512), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWP5cKX6OQtu"
      },
      "source": [
        "# Prototype initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-72NuWCJgKbf",
        "outputId": "c331a894-8f59-42ff-ba98-a753c52cd375"
      },
      "source": [
        "k_protos, vect_size = 10, 512\n",
        "kmedoids = KMedoids(n_clusters=k_protos, random_state=0).fit(sample_sent_vect)\n",
        "k_cents = kmedoids.cluster_centers_\n",
        "print(k_cents.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[db] k_protos:  10\n",
            "(10, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KI9aT_tZOY3Q"
      },
      "source": [
        "# Model training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRJ5ui5jg_ui"
      },
      "source": [
        "from protoryNet import ProtoryNet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NNK6ORKhtRV"
      },
      "source": [
        "pNet = ProtoryNet() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOQ5g8igi7HW",
        "outputId": "d98f8cc8-c066-4d3e-90ad-b955f49c17d8"
      },
      "source": [
        "model = pNet.createModel(k_cents)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.string, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n",
            "l2 =  KerasTensor(type_spec=TensorSpec(shape=(None, 512), dtype=tf.float32, name=None), name='keras_layer/StatefulPartitionedCall:0', description=\"created by layer 'keras_layer'\")\n",
            "l3 =  KerasTensor(type_spec=TensorSpec(shape=(1, None, 512), dtype=tf.float32, name=None), name='tf.expand_dims/ExpandDims:0', description=\"created by layer 'tf.expand_dims'\")\n",
            "proto_layer =  <protoryNet.ProtoryNet.createModel.<locals>.prototypeLayer object at 0x7fd210a4b150>\n",
            "distance_layer =  <protoryNet.ProtoryNet.createModel.<locals>.distanceLayer object at 0x7fd210c25690>\n",
            "dist_hot_vect  KerasTensor(type_spec=TensorSpec(shape=(None, None, 10), dtype=tf.float32, name=None), name='distance_layer/PartitionedCall:0', description=\"created by layer 'distance_layer'\")\n",
            "z =  KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense/Sigmoid:0', description=\"created by layer 'dense'\")\n",
            "db all layers:  [<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7fd2221cabd0>, <tensorflow_hub.keras_layer.KerasLayer object at 0x7fd2221b5ad0>, <tensorflow.python.keras.layers.core.TFOpLambda object at 0x7fd210b21b10>, <protoryNet.ProtoryNet.createModel.<locals>.prototypeLayer object at 0x7fd210a4b150>, <protoryNet.ProtoryNet.createModel.<locals>.distanceLayer object at 0x7fd210c25690>, <tensorflow.python.keras.layers.recurrent_v2.LSTM object at 0x7fd210b46f90>, <tensorflow.python.keras.layers.core.SlicingOpLambda object at 0x7fd210ae3a10>, <tensorflow.python.keras.layers.core.Dense object at 0x7fd210bece90>, <tensorflow.python.keras.layers.core.TFOpLambda object at 0x7fd2109b3e10>]\n",
            "[db] l =  input_1\n",
            "[db] l =  keras_layer\n",
            "[db] l =  tf.expand_dims\n",
            "[db] l =  proto_layer\n",
            "[db] l =  distance_layer\n",
            "[db] l =  lstm\n",
            "[db] l =  tf.__operators__.getitem\n",
            "[db] l =  dense\n",
            "[db] l =  tf.compat.v1.squeeze\n",
            "[db] model.input =  KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.string, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n",
            "[db] protoLayerName =  proto_layer\n",
            "[db] protoLayer =  <protoryNet.ProtoryNet.createModel.<locals>.prototypeLayer object at 0x7fd210a4b150>\n",
            "[db] protoLayer.output =  (<KerasTensor: shape=(None, None, 10) dtype=float32 (created by layer 'proto_layer')>, <KerasTensor: shape=(10, 512) dtype=float32 (created by layer 'proto_layer')>)\n",
            "[db] distanceLayer.output =  KerasTensor(type_spec=TensorSpec(shape=(None, None, 10), dtype=tf.float32, name=None), name='distance_layer/PartitionedCall:0', description=\"created by layer 'distance_layer'\")\n",
            "Model: \"custom_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None,)]                 0         \n",
            "_________________________________________________________________\n",
            "keras_layer (KerasLayer)     (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "tf.expand_dims (TFOpLambda)  (1, None, 512)            0         \n",
            "_________________________________________________________________\n",
            "proto_layer (prototypeLayer) ((None, None, 10), (10, 5 5120      \n",
            "_________________________________________________________________\n",
            "distance_layer (distanceLaye (None, None, 10)          0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  [(None, None, 128), (None 71168     \n",
            "_________________________________________________________________\n",
            "tf.__operators__.getitem (Sl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "_________________________________________________________________\n",
            "tf.compat.v1.squeeze (TFOpLa (1,)                      0         \n",
            "_________________________________________________________________\n",
            "model (Functional)           ((None, None, 10), (10, 5 256802944 \n",
            "_________________________________________________________________\n",
            "model_1 (Functional)         (None, None, 10)          256802944 \n",
            "=================================================================\n",
            "Total params: 256,874,241\n",
            "Trainable params: 256,874,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8kiIGwFTqGEZ",
        "outputId": "e419ffe8-9c75-40a6-ed33-8b261ebafb9c"
      },
      "source": [
        "pNet.train(x_train,y_train,x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  0\n",
            "i =   0\n",
            "[db] pro sent dist =  Tensor(\"model/proto_layer/StatefulPartitionedCall:0\", shape=(None, None, 10), dtype=float32)\n",
            "[db] r =  Tensor(\"Sum_2:0\", shape=(10,), dtype=float32)\n",
            "db y:  Tensor(\"data_1:0\", shape=(None,), dtype=int64) Tensor(\"strided_slice:0\", shape=(), dtype=int64)\n",
            "y_pred  Tensor(\"custom_model/tf.compat.v1.squeeze/Squeeze:0\", shape=(1,), dtype=float32)\n",
            "y_val  Tensor(\"ExpandDims:0\", shape=(1,), dtype=int64)\n",
            "[db] pro sent dist =  Tensor(\"model/proto_layer/StatefulPartitionedCall:0\", shape=(None, None, 10), dtype=float32)\n",
            "[db] r =  Tensor(\"Sum_2:0\", shape=(10,), dtype=float32)\n",
            "db y:  Tensor(\"data_1:0\", shape=(None,), dtype=int64) Tensor(\"strided_slice:0\", shape=(), dtype=int64)\n",
            "y_pred  Tensor(\"custom_model/tf.compat.v1.squeeze/Squeeze:0\", shape=(1,), dtype=float32)\n",
            "y_val  Tensor(\"ExpandDims:0\", shape=(1,), dtype=int64)\n",
            "1/1 [==============================] - 9s 9s/step - loss: 0.6975\n",
            "Evaluating y_pred, y  [0.49114528] 0 0\n",
            "Evaluating y_pred, y  [0.5002696] 1 1\n",
            "Evaluate on valid set:  0.3325942350332594\n",
            "This is the best eval res, saving the model...\n",
            "saving model now = 2021-08-12 21:27:10.836552\n",
            "date and time = 12_08_2021_21_27_10\n",
            "just saved\n",
            "i =   50\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.6679\n",
            "[db] pro sent dist =  Tensor(\"model/proto_layer/StatefulPartitionedCall:0\", shape=(None, None, 10), dtype=float32)\n",
            "[db] r =  Tensor(\"Sum_2:0\", shape=(10,), dtype=float32)\n",
            "db y:  Tensor(\"data_1:0\", shape=(32,), dtype=int64) Tensor(\"strided_slice:0\", shape=(), dtype=int64)\n",
            "y_pred  Tensor(\"custom_model/tf.compat.v1.squeeze/Squeeze:0\", shape=(1,), dtype=float32)\n",
            "y_val  Tensor(\"ExpandDims:0\", shape=(1,), dtype=int64)\n",
            "i =   100\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.8151\n",
            "i =   150\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.5903\n",
            "i =   200\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.8089\n",
            "Evaluating y_pred, y  [0.5388467] 1 0\n",
            "Evaluating y_pred, y  [0.5983809] 1 1\n",
            "Evaluate on valid set:  0.5221729490022173\n",
            "This is the best eval res, saving the model...\n",
            "saving model now = 2021-08-12 21:28:43.172624\n",
            "date and time = 12_08_2021_21_28_43\n",
            "just saved\n",
            "i =   250\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 1.0213\n",
            "i =   300\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.5151\n",
            "i =   350\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.0994\n",
            "i =   400\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 1.9109\n",
            "Evaluating y_pred, y  [0.4587981] 0 0\n",
            "Evaluating y_pred, y  [0.7707129] 1 1\n",
            "Evaluate on valid set:  0.770509977827051\n",
            "This is the best eval res, saving the model...\n",
            "saving model now = 2021-08-12 21:30:11.062047\n",
            "date and time = 12_08_2021_21_30_11\n",
            "just saved\n",
            "i =   450\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.4124\n",
            "i =   500\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.6684\n",
            "i =   550\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.2504\n",
            "i =   600\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.1981\n",
            "Evaluating y_pred, y  [0.38709483] 0 0\n",
            "Evaluating y_pred, y  [0.8577586] 1 1\n",
            "Evaluate on valid set:  0.8891352549889135\n",
            "This is the best eval res, saving the model...\n",
            "saving model now = 2021-08-12 21:31:38.041512\n",
            "date and time = 12_08_2021_21_31_38\n",
            "just saved\n",
            "i =   650\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.0210\n",
            "i =   700\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.4688\n",
            "i =   750\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 0.4783\n",
            "i =   800\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.1331\n",
            "Evaluating y_pred, y  [0.2618683] 0 0\n",
            "Evaluating y_pred, y  [0.9379593] 1 1\n",
            "Evaluate on valid set:  0.8891352549889135\n",
            "i =   850\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.0574\n",
            "i =   900\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3187\n",
            "i =   950\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3023\n",
            "i =   1000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3833\n",
            "Evaluating y_pred, y  [0.20679292] 0 0\n",
            "Evaluating y_pred, y  [0.9737138] 1 1\n",
            "Evaluate on valid set:  0.8980044345898004\n",
            "This is the best eval res, saving the model...\n",
            "saving model now = 2021-08-12 21:34:37.346595\n",
            "date and time = 12_08_2021_21_34_37\n",
            "just saved\n",
            "i =   1050\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.0096\n",
            "i =   1100\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 2.1521\n",
            "i =   1150\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.2563\n",
            "i =   1200\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 1.0790\n",
            "Evaluating y_pred, y  [0.2058522] 0 0\n",
            "Evaluating y_pred, y  [0.9837165] 1 1\n",
            "Evaluate on valid set:  0.9035476718403548\n",
            "This is the best eval res, saving the model...\n",
            "saving model now = 2021-08-12 21:36:04.477519\n",
            "date and time = 12_08_2021_21_36_04\n",
            "just saved\n",
            "i =   1250\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.2556\n",
            "i =   1300\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.5054\n",
            "i =   1350\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.0552\n",
            "i =   1400\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.0083\n",
            "Evaluating y_pred, y  [0.1346527] 0 0\n",
            "Evaluating y_pred, y  [0.9742363] 1 1\n",
            "Evaluate on valid set:  0.9124168514412417\n",
            "This is the best eval res, saving the model...\n",
            "saving model now = 2021-08-12 21:37:30.577732\n",
            "date and time = 12_08_2021_21_37_30\n",
            "just saved\n",
            "i =   1450\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.0673\n",
            "i =   1500\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 1.4943\n",
            "i =   1550\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.1147\n",
            "i =   1600\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.0597\n",
            "Evaluating y_pred, y  [0.09721024] 0 0\n",
            "Evaluating y_pred, y  [0.98695135] 1 1\n",
            "Evaluate on valid set:  0.9168514412416852\n",
            "This is the best eval res, saving the model...\n",
            "saving model now = 2021-08-12 21:38:57.100289\n",
            "date and time = 12_08_2021_21_38_57\n",
            "just saved\n",
            "i =   1650\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 1.3648\n",
            "i =   1700\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 3.0351\n",
            "i =   1750\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.0111\n",
            "i =   1800\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.0100\n",
            "Evaluating y_pred, y  [0.09891978] 0 0\n",
            "Evaluating y_pred, y  [0.9962351] 1 1\n",
            "Evaluate on valid set:  0.9301552106430155\n",
            "This is the best eval res, saving the model...\n",
            "saving model now = 2021-08-12 21:40:26.547641\n",
            "date and time = 12_08_2021_21_40_26\n",
            "just saved\n",
            "i =   1850\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.1891\n",
            "i =   1900\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.2571\n",
            "i =   1950\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.0160\n",
            "i =   2000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.0192\n",
            "Evaluating y_pred, y  [0.09580462] 0 0\n",
            "Evaluating y_pred, y  [0.99491817] 1 1\n",
            "Evaluate on valid set:  0.9168514412416852\n",
            "i =   2050\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.6127\n",
            "i =   2100\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.0363\n",
            "i =   2150\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.1489\n",
            "i =   2200\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.0071\n",
            "Evaluating y_pred, y  [0.08941401] 0 0\n",
            "Evaluating y_pred, y  [0.99091196] 1 1\n",
            "Evaluate on valid set:  0.9257206208425721\n",
            "i =   2250\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.0070\n",
            "i =   2300\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.0274\n",
            "i =   2350\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.0387\n",
            "i =   2400\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.0070\n",
            "Evaluating y_pred, y  [0.08304588] 0 0\n",
            "Evaluating y_pred, y  [0.9928645] 1 1\n",
            "Evaluate on valid set:  0.9356984478935698\n",
            "This is the best eval res, saving the model...\n",
            "saving model now = 2021-08-12 21:44:48.695276\n",
            "date and time = 12_08_2021_21_44_48\n",
            "just saved\n",
            "i =   2450\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.1954\n",
            "i =   2500\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.0060\n",
            "i =   2550\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.0069\n",
            "i =   2600\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.6432\n",
            "Evaluating y_pred, y  [0.06795555] 0 0\n",
            "Evaluating y_pred, y  [0.99514896] 1 1\n",
            "Evaluate on valid set:  0.926829268292683\n",
            "i =   2650\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.2255\n",
            "i =   2700\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.0933\n",
            "i =   2750\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.0530\n",
            "i =   2800\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.1445\n",
            "Evaluating y_pred, y  [0.08296543] 0 0\n",
            "Evaluating y_pred, y  [0.9951567] 1 1\n",
            "Evaluate on valid set:  0.9412416851441242\n",
            "This is the best eval res, saving the model...\n",
            "saving model now = 2021-08-12 21:47:40.946488\n",
            "date and time = 12_08_2021_21_47_40\n",
            "just saved\n",
            "i =   2850\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.0764\n",
            "i =   2900\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.5128\n",
            "i =   2950\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.0267\n",
            "i =   3000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.5961\n",
            "Evaluating y_pred, y  [0.08866401] 0 0\n",
            "Evaluating y_pred, y  [0.9896185] 1 1\n",
            "Evaluate on valid set:  0.9334811529933481\n",
            "i =   3050\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.0531\n",
            "i =   3100\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.0258\n",
            "i =   3150\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.0335\n",
            "i =   3200\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.0284\n",
            "Evaluating y_pred, y  [0.03948795] 0 0\n",
            "Evaluating y_pred, y  [0.99276286] 1 1\n",
            "Evaluate on valid set:  0.926829268292683\n",
            "i =   3250\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 1.2516\n",
            "i =   3300\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.0474\n",
            "i =   3350\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.0100\n",
            "i =   3400\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.2756\n",
            "Evaluating y_pred, y  [0.07768225] 0 0\n",
            "Evaluating y_pred, y  [0.99457365] 1 1\n",
            "Evaluate on valid set:  0.9101995565410199\n",
            "i =   3450\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.1244\n",
            "i =   3500\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.0140\n",
            "i =   3550\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.0402\n",
            "i =   3600\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.0076\n",
            "Evaluating y_pred, y  [0.04382966] 0 0\n",
            "Evaluating y_pred, y  [0.99120975] 1 1\n",
            "Evaluate on valid set:  0.9368070953436807\n",
            "Epoch  1\n",
            "i =   0\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 1.8601\n",
            "Evaluating y_pred, y  [0.0445135] 0 0\n",
            "Evaluating y_pred, y  [0.9916425] 1 1\n",
            "Evaluate on valid set:  0.9401330376940134\n",
            "i =   50\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.8543\n",
            "i =   100\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.0737\n",
            "i =   150\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.0164\n",
            "i =   200\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.0358\n",
            "Evaluating y_pred, y  [0.07456356] 0 0\n",
            "Evaluating y_pred, y  [0.9926392] 1 1\n",
            "Evaluate on valid set:  0.9434589800443459\n",
            "This is the best eval res, saving the model...\n",
            "saving model now = 2021-08-12 21:55:57.417294\n",
            "date and time = 12_08_2021_21_55_57\n",
            "just saved\n",
            "i =   250\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.0233\n",
            "i =   300\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.0203\n",
            "i =   350\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.0077\n",
            "i =   400\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 4.2165\n",
            "Evaluating y_pred, y  [0.02670782] 0 0\n",
            "Evaluating y_pred, y  [0.99620074] 1 1\n",
            "Evaluate on valid set:  0.9490022172949002\n",
            "This is the best eval res, saving the model...\n",
            "saving model now = 2021-08-12 21:57:25.363862\n",
            "date and time = 12_08_2021_21_57_25\n",
            "just saved\n",
            "i =   450\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.0295\n",
            "i =   500\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.2703\n",
            "i =   550\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.0178\n",
            "i =   600\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.0197\n",
            "Evaluating y_pred, y  [0.071376] 0 0\n",
            "Evaluating y_pred, y  [0.9877059] 1 1\n",
            "Evaluate on valid set:  0.9412416851441242\n",
            "i =   650\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.0633\n",
            "i =   700\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.1606\n",
            "i =   750\n",
            "2/2 [==============================] - 0s 156ms/step - loss: 0.0745\n",
            "i =   800\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.0301\n",
            "Evaluating y_pred, y  [0.02681706] 0 0\n",
            "Evaluating y_pred, y  [0.9929763] 1 1\n",
            "Evaluate on valid set:  0.950110864745011\n",
            "This is the best eval res, saving the model...\n",
            "saving model now = 2021-08-12 22:00:23.606305\n",
            "date and time = 12_08_2021_22_00_23\n",
            "just saved\n",
            "i =   850\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.0127\n",
            "i =   900\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.0502\n",
            "i =   950\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.0321\n",
            "i =   1000\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.3054\n",
            "Evaluating y_pred, y  [0.05708645] 0 0\n",
            "Evaluating y_pred, y  [0.99471456] 1 1\n",
            "Evaluate on valid set:  0.9545454545454546\n",
            "This is the best eval res, saving the model...\n",
            "saving model now = 2021-08-12 22:01:50.565737\n",
            "date and time = 12_08_2021_22_01_50\n",
            "just saved\n",
            "i =   1050\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.0151\n",
            "i =   1100\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.0906\n",
            "i =   1150\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.0463\n",
            "i =   1200\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 1.0025\n",
            "Evaluating y_pred, y  [0.05893803] 0 0\n",
            "Evaluating y_pred, y  [0.99549437] 1 1\n",
            "Evaluate on valid set:  0.9467849223946785\n",
            "i =   1250\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.0589\n",
            "i =   1300\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3625\n",
            "i =   1350\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.0273\n",
            "i =   1400\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.0050\n",
            "Evaluating y_pred, y  [0.01490359] 0 0\n",
            "Evaluating y_pred, y  [0.9979814] 1 1\n",
            "Evaluate on valid set:  0.958980044345898\n",
            "This is the best eval res, saving the model...\n",
            "saving model now = 2021-08-12 22:04:47.240078\n",
            "date and time = 12_08_2021_22_04_47\n",
            "just saved\n",
            "i =   1450\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.0125\n",
            "i =   1500\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.0085\n",
            "i =   1550\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.0249\n",
            "i =   1600\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.0178\n",
            "Evaluating y_pred, y  [0.03304875] 0 0\n",
            "Evaluating y_pred, y  [0.99613225] 1 1\n",
            "Evaluate on valid set:  0.958980044345898\n",
            "i =   1650\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.6300\n",
            "i =   1700\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.8868\n",
            "i =   1750\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.0079\n",
            "i =   1800\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.0116\n",
            "Evaluating y_pred, y  [0.01461382] 0 0\n",
            "Evaluating y_pred, y  [0.9951611] 1 1\n",
            "Evaluate on valid set:  0.9423503325942351\n",
            "i =   1850\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.0914\n",
            "i =   1900\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.1050\n",
            "i =   1950\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.0096\n",
            "i =   2000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.0114\n",
            "Evaluating y_pred, y  [0.01462533] 0 0\n",
            "Evaluating y_pred, y  [0.9964896] 1 1\n",
            "Evaluate on valid set:  0.950110864745011\n",
            "i =   2050\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.0645\n",
            "i =   2100\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.0111\n",
            "i =   2150\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.0136\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-f5fc0eaa5da6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/protoryNet.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x_train, y_train, x_test, y_test)\u001b[0m\n\u001b[1;32m    222\u001b[0m                               \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                               validation_data=None)\n\u001b[0m\u001b[1;32m    225\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1190\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1192\u001b[0;31m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m           \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expect x to be a non-empty array or dataset.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 867\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 867\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    513\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \"\"\"\n\u001b[1;32m   1093\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1058\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x72NlZ9ysEy7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}